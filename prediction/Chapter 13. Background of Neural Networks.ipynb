{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cbfc129",
   "metadata": {},
   "source": [
    "# Code 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafe6f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    '''\n",
    "    ranges from  0 to 1\n",
    "    '''\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "class Perceptron:\n",
    "    def __init__(self, num_inputs):\n",
    "        # initialize the weights randomly, and set the bias to 1\n",
    "        self.w1 = np.random.random(num_inputs)\n",
    "        self.b1 = 1\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # compute activation for input layer\n",
    "        fX = np.dot(X, self.w1) + self.b1\n",
    "        # non-linear transform\n",
    "        activation = sigmoid(fX)\n",
    "        # check threshold: for sigmoid, use 0.5, for tanh, use 0\n",
    "        y = np.where(fX >= 0.5, 1, -1)\n",
    "        return y\n",
    "    \n",
    "    def fit(self, train_data, train_labels, num_epochs=20):\n",
    "        models = []\n",
    "        print(num_epochs)\n",
    "        for epoch in range(1, num_epochs+1):\n",
    "            print(epoch)\n",
    "            for (X, y) in zip(train_data, train_labels):\n",
    "                pred_label = self.predict(X)\n",
    "\n",
    "                if pred_label != y:\n",
    "                    print('update')\n",
    "                    self.w1 = self.w1 + (X * y)\n",
    "                    self.b1 = self.b1 + y\n",
    "\n",
    "            models.append((self.w1, self.b1))\n",
    "\n",
    "        return models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671ad8a5",
   "metadata": {},
   "source": [
    "# Code 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605399e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "and_data = np.array([[1, 1], [1, 0], [0, 1], [0, 0]])\n",
    "and_labels = np.array([1, -1, -1, -1])\n",
    "\n",
    "or_data = np.array([[1, 1], [1, 0], [0, 1], [0, 0]])\n",
    "or_labels = np.array([1, 1, 1, -1])\n",
    "\n",
    "xor_data = np.array([[1, 1], [1, 0], [0, 1], [0, 0]])\n",
    "xor_labels = np.array([-1, 1, 1, -1])\n",
    "\n",
    "# initialize perceptron\n",
    "perceptron = Perceptron(2)\n",
    "\n",
    "iters = perceptron.fit(and_data, and_labels, num_epochs=10)\n",
    "and_predictions = perceptron.predict(and_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef7801d",
   "metadata": {},
   "source": [
    "# Code 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19da389",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "\n",
    "# input: a sequence  of 2 integers\n",
    "main_input = Input(shape=(2,), name='main_input')\n",
    "\n",
    "# add the output layer\n",
    "output = Dense(2, activation='hard_sigmoid', name='output', kernel_initializer='glorot_uniform')(main_input)\n",
    "\n",
    "# f(X) = sigmoid(X*W + b)\n",
    "\n",
    "# the model is specified by connecting input and output\n",
    "perceptron_keras = Model(inputs=[main_input], outputs=[output])\n",
    "\n",
    "# compile the model\n",
    "perceptron_keras.compile(loss='binary_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# train the model on a validation set and dave the loss and accuracy for every epoch\n",
    "history = perceptron_keras.fit(X, y,\n",
    "                    epochs=15,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.2\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e698e12f",
   "metadata": {},
   "source": [
    "# Code 27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfc4804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: a sequence  of 2 integers\n",
    "mlp_input = Input(shape=(2,), name='main_input')\n",
    "\n",
    "# add a hidden layer\n",
    "mlp_hidden = Dense(16, activation='relu', name='hidden', kernel_initializer='glorot_uniform')(mlp_input)\n",
    "\n",
    "# add the output layer\n",
    "mlp_output = Dense(2, activation='softmax', name='output', kernel_initializer='glorot_uniform')(mlp_hidden)\n",
    "\n",
    "# the model is specified by connecting input and output\n",
    "mlp = Model(inputs=[mlp_input], outputs=[mlp_output])\n",
    "\n",
    "mlp.compile(loss='binary_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy']\n",
    "           )\n",
    "\n",
    "mlp_history = mlp.fit(X, y,\n",
    "                    epochs=50,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fafd7b",
   "metadata": {},
   "source": [
    "# Code 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688c9a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout = Dropout(0.3, name='dropout')(layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb241ea",
   "metadata": {},
   "source": [
    "# Code 29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd95e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect known word tokens and tags\n",
    "wordset, labelset = set(), set()\n",
    "\n",
    "# collect all unique labels\n",
    "labelset.update(set(train_labels))\n",
    "\n",
    "# collect all word types in the training data\n",
    "for words in train_instances:\n",
    "    wordset.update(set(words))\n",
    "\n",
    "# map words and tags into integer IDs\n",
    "PAD = '-PAD-'\n",
    "UNK = '-UNK-'\n",
    "word2int = {word: i + 2 for i, word in enumerate(sorted(wordset))}\n",
    "word2int[PAD] = 0  # special token for padding\n",
    "word2int[UNK] = 1  # special token for unknown words\n",
    " \n",
    "label2int = {label: i for i, label in enumerate(sorted(labelset))}\n",
    "# structure to translate IDs back to labels\n",
    "int2label = {i:label for label, i in label2int.items()}\n",
    "\n",
    "# helper function\n",
    "def convert2ints(instances):\n",
    "    result = []\n",
    "    for words in instances:\n",
    "        # replace words with ID, use 1 for unknown words\n",
    "        word_ints = [word2int.get(word, 1) for word in words]\n",
    "        result.append(word_ints)\n",
    "    return result\n",
    "\n",
    "# convert data and labels                          \n",
    "train_instances_int = convert2ints(train_instances)\n",
    "train_labels_int = [label2int[label] for label in train_labels]\n",
    "\n",
    "test_instances_int = convert2ints(test_instances)\n",
    "test_labels_int = [label2int[label] for label in test_labels]\n",
    "\n",
    "# convert labels to 1-hot encoding\n",
    "from keras.utils import to_categorical\n",
    "train_labels_1hot = to_categorical(train_labels_int, len(label2int))\n",
    "test_labels_1hot = to_categorical(test_labels_int, len(label2int))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba1e579",
   "metadata": {},
   "source": [
    "# Code 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61833124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute 95th percentile of training sentence lengths\n",
    "L = sorted(map(len, train_instances))\n",
    "MAX_LENGTH = L[int(len(L) * 0.95)]\n",
    "\n",
    "# apply padding\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "train_instances_int = pad_sequences(train_instances_int, padding='post', maxlen=MAX_LENGTH)\n",
    "test_instances_int = pad_sequences(test_instances_int, padding='post', maxlen=MAX_LENGTH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
