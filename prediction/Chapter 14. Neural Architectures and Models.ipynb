{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80be595e",
   "metadata": {},
   "source": [
    "# Code 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa88e9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Embedding\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers import GlobalMaxPooling1D, Dropout\n",
    "from keras.layers.core import Dense, Activation\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "# set parameters of matrices and convolution\n",
    "embedding_dim = 64\n",
    "nb_filter = 64\n",
    "filter_length = 3\n",
    "\n",
    "inputs = Input((MAX_LENGTH, ), \n",
    "               name='word_IDs')\n",
    "embeddings = Embedding(len(word2int), \n",
    "                       embedding_dim, \n",
    "                       input_length=MAX_LENGTH)(inputs)\n",
    "convolution = Conv1D(filters=nb_filter,  # Number of filters\n",
    "                    kernel_size=filter_length, #  stride length of each filter\n",
    "                    padding='same',  #valid: don't go off edge; same: use padding before applying filter\n",
    "                    activation='relu',\n",
    "                    strides=1)(embeddings)\n",
    "pooling = GlobalMaxPooling1D()(convolution)\n",
    "dropout1 = Dropout(0.2)(pooling)\n",
    "dense = Dense(32, activation='relu')(dropout1)\n",
    "dropout2 = Dropout(0.2)(dense)\n",
    "output = Dense(len(label2int), activation='softmax')(dropout2)\n",
    "\n",
    "model = Model(inputs=[inputs], outputs=[output])\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ed99b9",
   "metadata": {},
   "source": [
    "# Code 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0640cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch size can have a huge effect on performance!\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "\n",
    "history = model.fit(train_instances_int, train_labels_1hot,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(dev_instances_int, dev_labels_1hot)\n",
    "                   )\n",
    "\n",
    "loss, accuracy = model.evaluate(test_instances_int, test_labels_1hot,\n",
    "                                batch_size=batch_size,\n",
    "                                verbose=False)\n",
    "\n",
    "print(\"\\nTesting Accuracy:  {:.4f}\".format(accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f423ee",
   "metadata": {},
   "source": [
    "# Code 33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e765e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Bi-)LSTM\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Embedding\n",
    "from keras.layers import Bidirectional, LSTM\n",
    "from keras.layers import Dropout, Dense, Activation\n",
    "import numpy as np\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "inputs = Input((MAX_LENGTH, ), \n",
    "               name='word_IDs')\n",
    "embeddings = Embedding(input_dim=len(word2int), \n",
    "                       output_dim=128, \n",
    "                       mask_zero=True, \n",
    "                       name='embeddings')(inputs)\n",
    "lstm = LSTM(units=256,\n",
    "              return_sequences=True,\n",
    "              name=\"LSTM\")(embeddings)\n",
    "# for a Bi-LSTM, replace the line above with this:\n",
    "# from keras.layers import Bidirectional\n",
    "#bilstm = Bidirectional(LSTM(units=256, \n",
    "#                            return_sequences=True), \n",
    "#                       name=\"Bi-LSTM\")(embeddings)\n",
    "dropout = Dropout(0.3, name='dropout')(lstm)\n",
    "lstm_out = Dense(len(tag2int), name='output')(dropout)\n",
    "output = Activation('softmax', name='softmax')(lstm_out)\n",
    "\n",
    "model = Model(inputs=[inputs], outputs=[output])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee3cc79",
   "metadata": {},
   "source": [
    "# Code 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d171f2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 5\n",
    "\n",
    "# compile the model we have defined above\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy']\n",
    "             )\n",
    "\n",
    "# run training and capture ouput log\n",
    "history = model.fit(train_sentences, train_tags_1hot,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
